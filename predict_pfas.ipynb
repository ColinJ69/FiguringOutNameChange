{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtpo0o3cT3tEEcCRAsyg32",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ColinJ69/HydroHaven/blob/main/predict_pfas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pickle\n",
        "\n",
        "df = pd.read_excel('pfas (1).xlsx')\n",
        "t1 = []\n",
        "num = 0\n",
        "labels = []\n",
        "sources = []\n",
        "\n",
        "#print(df.loc[156].tolist()[2:])\n",
        "\n",
        "features = ['Well depth', 'PP_1km', 'PP_4km', 'PP_12km','AFFF', 'KP_50km', 'Nearest_KP', 'AFF_Acc', 'Basin', 'KP_Name', 'AFFF_Con', 'pm10', 'pm25', 'so', 'lat', 'lng', 'co', 'no','silt', 'slope', 'water','temp', 'humid', 'dew', 'rain', 'evapo', 'wind']\n",
        "for i in range(0, 340):\n",
        "\n",
        "\n",
        "    #print(df.loc[i]['Split'])\n",
        "    labels.append(int(df.loc[i]['Split']))\n",
        "    sources.append(df.loc[i]['County'])\n",
        "\n",
        "    #t1.append(df.loc[i].tolist()[2:])\n",
        "    numeric_row = pd.to_numeric(df.loc[i].tolist()[2:34], errors='coerce')\n",
        "\n",
        "    t1.append(numeric_row.tolist())\n",
        "\n",
        "print(df['Split'].value_counts())\n",
        "print(t1[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gQGN3OBQn0J7",
        "outputId": "a33ae4d3-0357-4127-f8d3-5650be7cb162"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split\n",
            "0    268\n",
            "1     72\n",
            "Name: count, dtype: int64\n",
            "[36.044422, -79.536914, 720.0, 80042.0, 4.0, 5.0, 18.0, 5.0, 10.65, 37.0, 1.0, 21.85733397271898, 88.40057299931844, 19.69386168585883, 0.4969444446472658, 0.1062786542539672, 9.569445922142929, 21.78431311978234, 0.4322277778345677, 13.13, 11.57, 0.19, 220.24, 2.23, 35.47, 0.0, 30.03, 8.05, 0.137, 6.0, 2.0, 3.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn .metrics import roc_auc_score, f1_score, recall_score, precision_score"
      ],
      "metadata": {
        "id": "1-4xIhgZ3wx9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(labels)/130)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDdRoROk9h0O",
        "outputId": "e71356b9-9a37-4a12-9c2b-99fa64964e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5538461538461539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import ADASYN"
      ],
      "metadata": {
        "id": "i-4gezkXJ987"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adasyn = ADASYN(sampling_strategy='minority')\n"
      ],
      "metadata": {
        "id": "Ts6nGnH6J9lo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "7dwAgaXyhg0m"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTE(random_state=12)\n",
        "sm.fit(t1, labels)\n",
        "#t1, labels = sm.fit_resample(t1, labels)\n",
        "sm.fit(t1, labels)\n",
        "t1, labels = sm.fit_resample(t1, labels)\n"
      ],
      "metadata": {
        "id": "NTC0Ill4hdiR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Split'].isnull().sum())\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "rus = RandomUnderSampler(sampling_strategy='not minority', random_state=12)\n",
        "df_balanced, balanced_labels = rus.fit_resample(t1, labels)\n",
        "print(pd.Series(balanced_labels).value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9xScNgM4g1Q",
        "outputId": "157cadb4-34a2-4e29-b461-127926e737b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0    72\n",
            "1    72\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_balanced = df_balanced.drop('County', axis=1)\n",
        "df_balanced = df_balanced.drop('Split', axis=1)\n",
        "df_balanced = np.array(df_balanced)\n",
        "print(round(len(sorted(balanced_labels)[sorted(balanced_labels).index(1):])/len(balanced_labels),2))"
      ],
      "metadata": {
        "id": "LVhE2HZ7viUd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "791dcefc-5506-459d-d86b-52281ea3cef5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'drop'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8e40578dc17f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_balanced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_balanced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'County'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_balanced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_balanced\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Split'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_balanced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_balanced\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbalanced_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbalanced_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbalanced_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'drop'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(t1, labels, test_size=0.2, random_state=12)\n",
        "\n",
        "\n",
        "print(pd.Series(y_test).value_counts())\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "auc = np.round(roc_auc_score(y_test, y_pred), 10)\n",
        "print(auc)\n",
        "f1 = np.round(f1_score(y_test, y_pred), 10)\n",
        "print(f1)\n",
        "recall = np.round(recall_score(y_test, y_pred), 10)\n",
        "print(recall)\n",
        "precision = np.round(precision_score(y_test, y_pred, zero_division=1), 10)\n",
        "print(precision)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "\n",
        "#print(np.max(rf.predict_proba(X_testt), axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZssenmKTwrbw",
        "outputId": "e824caec-0bdb-4182-8044-b15172d2f623"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    57\n",
            "1    51\n",
            "Name: count, dtype: int64\n",
            "0.9287925697\n",
            "0.9259259259\n",
            "0.9803921569\n",
            "0.8771929825\n",
            "Accuracy: 92.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "importances = rf.feature_importances_\n",
        "std = list(np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0))\n",
        "e = dict((n, l) for n, l in zip(features, std))\n",
        "print(len(std))\n",
        "sorted_dict = {k: round((v *100), 2)  for k, v in reversed(sorted(e.items(), key=lambda item: item[1]))}\n",
        "print(sorted_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-070WM62vleq",
        "outputId": "98775c94-5dcf-4607-db76-2b62c6cd2717"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "{'Nearest_KP': 14.8, 'temp': 13.83, 'evapo': 10.63, 'KP_50km': 6.85, 'AFFF_Con': 6.54, 'pm25': 6.51, 'AFF_Acc': 6.16, 'pm10': 5.17, 'no': 5.01, 'so': 4.8, 'PP_1km': 4.57, 'AFFF': 4.37, 'water': 3.04, 'co': 2.85, 'lng': 2.44, 'lat': 2.37, 'KP_Name': 2.13, 'slope': 2.1, 'Well depth': 1.96, 'Basin': 1.91, 'rain': 1.91, 'humid': 1.79, 'dew': 1.76, 'PP_12km': 1.7, 'PP_4km': 1.69, 'wind': 1.5, 'silt': 1.32}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "X_train, X_test, y_train, y_test = train_test_split(t1, labels, test_size=0.2, random_state=42)\n",
        "model = xgb.XGBClassifier(n_estimators=100, eval_metric='logloss')\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_pred, y_test)\n",
        "\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "auc = np.round(roc_auc_score(y_test, y_pred), 10)\n",
        "print(auc)\n",
        "f1 = np.round(f1_score(y_test, y_pred), 10)\n",
        "print(f1)\n",
        "recall = np.round(recall_score(y_test, y_pred), 10)\n",
        "print(recall)\n",
        "precision = np.round(precision_score(y_test, y_pred), 10)\n",
        "print(precision)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkN0bDvi2-uw",
        "outputId": "c354f936-e090-47cc-99b5-395fb9eaca57"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.52%\n",
            "0.9354395604\n",
            "0.9333333333\n",
            "0.9423076923\n",
            "0.9245283019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Example usage\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "predictions = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "auc = np.round(roc_auc_score(y_test, y_pred), 10)\n",
        "print(auc)\n",
        "f1 = np.round(f1_score(y_test, y_pred), 10)\n",
        "print(f1)\n",
        "recall = np.round(recall_score(y_test, y_pred), 10)\n",
        "print(recall)\n",
        "precision = np.round(precision_score(y_test, y_pred), 10)\n",
        "print(precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX47vEmmSBLF",
        "outputId": "94b7f670-c37e-4bcf-a55e-45ca08b7bc1b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 85.19%\n",
            "0.9354395604\n",
            "0.9333333333\n",
            "0.9423076923\n",
            "0.9245283019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "modellgr = LogisticRegression(max_iter=100)\n",
        "modellgr.fit(X_train, y_train)\n",
        "y_predlgr = modellgr.predict(X_test)\n",
        "accuracylgr = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracylgr}')\n",
        "auclgr = np.round(roc_auc_score(y_test, y_pred), 10)\n",
        "print(auclgr)\n",
        "f1lgr = np.round(f1_score(y_test, y_pred), 10)\n",
        "print(f1lgr)\n",
        "recalllgr = np.round(recall_score(y_test, y_pred), 10)\n",
        "print(recalllgr)\n",
        "precisionlgr = np.round(precision_score(y_test, y_pred), 10)\n",
        "print(precisionlgr)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3mUpvMUNLn5",
        "outputId": "dbc81f6b-1ad0-4ebf-e990-c4065ec5165c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9351851851851852\n",
            "0.9354395604\n",
            "0.9333333333\n",
            "0.9423076923\n",
            "0.9245283019\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "InPHAeMvPEKU",
        "outputId": "df841982-9b30-44d7-9637-e0a86251ff8c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.2.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "model = CatBoostClassifier(loss_function='Logloss')\n",
        "model.fit(X_train, y_train, verbose=100)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "auc = np.round(roc_auc_score(y_test, y_pred), 10)\n",
        "print(auc)\n",
        "f1 = np.round(f1_score(y_test, y_pred), 10)\n",
        "print(f1)\n",
        "recall = np.round(recall_score(y_test, y_pred), 10)\n",
        "print(recall)\n",
        "precision = np.round(precision_score(y_test, y_pred), 10)\n",
        "print(precision)\n",
        "\n",
        "with open('model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwFzVQPAO7EA",
        "outputId": "fe72e85e-344a-4398-93b9-3c9fedf5bd80"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.007171\n",
            "0:\tlearn: 0.6857792\ttotal: 7.66ms\tremaining: 7.66s\n",
            "100:\tlearn: 0.3310009\ttotal: 718ms\tremaining: 6.39s\n",
            "200:\tlearn: 0.2185737\ttotal: 1.42s\tremaining: 5.65s\n",
            "300:\tlearn: 0.1640088\ttotal: 2.13s\tremaining: 4.96s\n",
            "400:\tlearn: 0.1304580\ttotal: 2.83s\tremaining: 4.23s\n",
            "500:\tlearn: 0.1082823\ttotal: 3.52s\tremaining: 3.51s\n",
            "600:\tlearn: 0.0913146\ttotal: 4.26s\tremaining: 2.83s\n",
            "700:\tlearn: 0.0777673\ttotal: 4.96s\tremaining: 2.11s\n",
            "800:\tlearn: 0.0672489\ttotal: 5.65s\tremaining: 1.4s\n",
            "900:\tlearn: 0.0579767\ttotal: 6.36s\tremaining: 699ms\n",
            "999:\tlearn: 0.0508863\ttotal: 7.06s\tremaining: 0us\n",
            "Accuracy: 0.9629629629629629\n",
            "0.9629120879\n",
            "0.9615384615\n",
            "0.9615384615\n",
            "0.9615384615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities = model.predict_proba(X_test)\n",
        "print(X_test[3])\n",
        "for i, prob in enumerate(probabilities):\n",
        "    print(f\"Input {i}: Class 0 confidence = {prob[0]:.4f}, Class 1 confidence = {prob[1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s9r7XFqTHcT",
        "outputId": "1be01523-ec50-4d2c-fd0d-0211b8f13c1e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 1.0, 4.0, 31.0, 2.0, 3.0, 21.73, 1.0, 1.0, 27.0, 3.0, 13.93, 11.62, 0.11, 35.862601, -79.828221, 179.07, 3.02, 32.18, 8.89, 0.113, 21.78275065951877, 87.97759965260823, 19.51344503296746, 0.4741666698414418, 0.1070007027293387, 9.71981692140301]\n",
            "Input 0: Class 0 confidence = 0.9855, Class 1 confidence = 0.0145\n",
            "Input 1: Class 0 confidence = 0.4633, Class 1 confidence = 0.5367\n",
            "Input 2: Class 0 confidence = 0.7452, Class 1 confidence = 0.2548\n",
            "Input 3: Class 0 confidence = 0.0155, Class 1 confidence = 0.9845\n",
            "Input 4: Class 0 confidence = 0.9704, Class 1 confidence = 0.0296\n",
            "Input 5: Class 0 confidence = 0.9722, Class 1 confidence = 0.0278\n",
            "Input 6: Class 0 confidence = 0.9876, Class 1 confidence = 0.0124\n",
            "Input 7: Class 0 confidence = 0.0978, Class 1 confidence = 0.9022\n",
            "Input 8: Class 0 confidence = 0.9428, Class 1 confidence = 0.0572\n",
            "Input 9: Class 0 confidence = 0.4195, Class 1 confidence = 0.5805\n",
            "Input 10: Class 0 confidence = 0.0367, Class 1 confidence = 0.9633\n",
            "Input 11: Class 0 confidence = 0.9785, Class 1 confidence = 0.0215\n",
            "Input 12: Class 0 confidence = 0.9800, Class 1 confidence = 0.0200\n",
            "Input 13: Class 0 confidence = 0.0684, Class 1 confidence = 0.9316\n",
            "Input 14: Class 0 confidence = 0.9632, Class 1 confidence = 0.0368\n",
            "Input 15: Class 0 confidence = 0.1115, Class 1 confidence = 0.8885\n",
            "Input 16: Class 0 confidence = 0.7831, Class 1 confidence = 0.2169\n",
            "Input 17: Class 0 confidence = 0.0204, Class 1 confidence = 0.9796\n",
            "Input 18: Class 0 confidence = 0.9380, Class 1 confidence = 0.0620\n",
            "Input 19: Class 0 confidence = 0.0106, Class 1 confidence = 0.9894\n",
            "Input 20: Class 0 confidence = 0.9962, Class 1 confidence = 0.0038\n",
            "Input 21: Class 0 confidence = 0.4356, Class 1 confidence = 0.5644\n",
            "Input 22: Class 0 confidence = 0.9743, Class 1 confidence = 0.0257\n",
            "Input 23: Class 0 confidence = 0.9622, Class 1 confidence = 0.0378\n",
            "Input 24: Class 0 confidence = 0.0404, Class 1 confidence = 0.9596\n",
            "Input 25: Class 0 confidence = 0.0673, Class 1 confidence = 0.9327\n",
            "Input 26: Class 0 confidence = 0.0341, Class 1 confidence = 0.9659\n",
            "Input 27: Class 0 confidence = 0.0246, Class 1 confidence = 0.9754\n",
            "Input 28: Class 0 confidence = 0.0911, Class 1 confidence = 0.9089\n",
            "Input 29: Class 0 confidence = 0.0984, Class 1 confidence = 0.9016\n",
            "Input 30: Class 0 confidence = 0.3783, Class 1 confidence = 0.6217\n",
            "Input 31: Class 0 confidence = 0.9254, Class 1 confidence = 0.0746\n",
            "Input 32: Class 0 confidence = 0.0177, Class 1 confidence = 0.9823\n",
            "Input 33: Class 0 confidence = 0.9368, Class 1 confidence = 0.0632\n",
            "Input 34: Class 0 confidence = 0.4816, Class 1 confidence = 0.5184\n",
            "Input 35: Class 0 confidence = 0.2688, Class 1 confidence = 0.7312\n",
            "Input 36: Class 0 confidence = 0.2704, Class 1 confidence = 0.7296\n",
            "Input 37: Class 0 confidence = 0.0439, Class 1 confidence = 0.9561\n",
            "Input 38: Class 0 confidence = 0.0714, Class 1 confidence = 0.9286\n",
            "Input 39: Class 0 confidence = 0.1174, Class 1 confidence = 0.8826\n",
            "Input 40: Class 0 confidence = 0.1165, Class 1 confidence = 0.8835\n",
            "Input 41: Class 0 confidence = 0.0402, Class 1 confidence = 0.9598\n",
            "Input 42: Class 0 confidence = 0.9687, Class 1 confidence = 0.0313\n",
            "Input 43: Class 0 confidence = 0.9959, Class 1 confidence = 0.0041\n",
            "Input 44: Class 0 confidence = 0.9938, Class 1 confidence = 0.0062\n",
            "Input 45: Class 0 confidence = 0.1151, Class 1 confidence = 0.8849\n",
            "Input 46: Class 0 confidence = 0.9966, Class 1 confidence = 0.0034\n",
            "Input 47: Class 0 confidence = 0.1321, Class 1 confidence = 0.8679\n",
            "Input 48: Class 0 confidence = 0.0257, Class 1 confidence = 0.9743\n",
            "Input 49: Class 0 confidence = 0.9889, Class 1 confidence = 0.0111\n",
            "Input 50: Class 0 confidence = 0.0245, Class 1 confidence = 0.9755\n",
            "Input 51: Class 0 confidence = 0.0491, Class 1 confidence = 0.9509\n",
            "Input 52: Class 0 confidence = 0.6118, Class 1 confidence = 0.3882\n",
            "Input 53: Class 0 confidence = 0.0464, Class 1 confidence = 0.9536\n",
            "Input 54: Class 0 confidence = 0.0245, Class 1 confidence = 0.9755\n",
            "Input 55: Class 0 confidence = 0.8740, Class 1 confidence = 0.1260\n",
            "Input 56: Class 0 confidence = 0.1485, Class 1 confidence = 0.8515\n",
            "Input 57: Class 0 confidence = 0.0311, Class 1 confidence = 0.9689\n",
            "Input 58: Class 0 confidence = 0.9801, Class 1 confidence = 0.0199\n",
            "Input 59: Class 0 confidence = 0.0301, Class 1 confidence = 0.9699\n",
            "Input 60: Class 0 confidence = 0.1513, Class 1 confidence = 0.8487\n",
            "Input 61: Class 0 confidence = 0.0173, Class 1 confidence = 0.9827\n",
            "Input 62: Class 0 confidence = 0.0576, Class 1 confidence = 0.9424\n",
            "Input 63: Class 0 confidence = 0.0153, Class 1 confidence = 0.9847\n",
            "Input 64: Class 0 confidence = 0.3676, Class 1 confidence = 0.6324\n",
            "Input 65: Class 0 confidence = 0.9838, Class 1 confidence = 0.0162\n",
            "Input 66: Class 0 confidence = 0.9650, Class 1 confidence = 0.0350\n",
            "Input 67: Class 0 confidence = 0.9513, Class 1 confidence = 0.0487\n",
            "Input 68: Class 0 confidence = 0.9932, Class 1 confidence = 0.0068\n",
            "Input 69: Class 0 confidence = 0.0625, Class 1 confidence = 0.9375\n",
            "Input 70: Class 0 confidence = 0.9814, Class 1 confidence = 0.0186\n",
            "Input 71: Class 0 confidence = 0.0719, Class 1 confidence = 0.9281\n",
            "Input 72: Class 0 confidence = 0.9919, Class 1 confidence = 0.0081\n",
            "Input 73: Class 0 confidence = 0.1484, Class 1 confidence = 0.8516\n",
            "Input 74: Class 0 confidence = 0.9522, Class 1 confidence = 0.0478\n",
            "Input 75: Class 0 confidence = 0.0476, Class 1 confidence = 0.9524\n",
            "Input 76: Class 0 confidence = 0.9614, Class 1 confidence = 0.0386\n",
            "Input 77: Class 0 confidence = 0.6941, Class 1 confidence = 0.3059\n",
            "Input 78: Class 0 confidence = 0.9379, Class 1 confidence = 0.0621\n",
            "Input 79: Class 0 confidence = 0.9926, Class 1 confidence = 0.0074\n",
            "Input 80: Class 0 confidence = 0.9956, Class 1 confidence = 0.0044\n",
            "Input 81: Class 0 confidence = 0.1577, Class 1 confidence = 0.8423\n",
            "Input 82: Class 0 confidence = 0.0718, Class 1 confidence = 0.9282\n",
            "Input 83: Class 0 confidence = 0.8778, Class 1 confidence = 0.1222\n",
            "Input 84: Class 0 confidence = 0.9927, Class 1 confidence = 0.0073\n",
            "Input 85: Class 0 confidence = 0.0126, Class 1 confidence = 0.9874\n",
            "Input 86: Class 0 confidence = 0.0408, Class 1 confidence = 0.9592\n",
            "Input 87: Class 0 confidence = 0.2215, Class 1 confidence = 0.7785\n",
            "Input 88: Class 0 confidence = 0.1747, Class 1 confidence = 0.8253\n",
            "Input 89: Class 0 confidence = 0.9764, Class 1 confidence = 0.0236\n",
            "Input 90: Class 0 confidence = 0.1820, Class 1 confidence = 0.8180\n",
            "Input 91: Class 0 confidence = 0.0136, Class 1 confidence = 0.9864\n",
            "Input 92: Class 0 confidence = 0.9795, Class 1 confidence = 0.0205\n",
            "Input 93: Class 0 confidence = 0.0362, Class 1 confidence = 0.9638\n",
            "Input 94: Class 0 confidence = 0.9738, Class 1 confidence = 0.0262\n",
            "Input 95: Class 0 confidence = 0.5950, Class 1 confidence = 0.4050\n",
            "Input 96: Class 0 confidence = 0.0945, Class 1 confidence = 0.9055\n",
            "Input 97: Class 0 confidence = 0.1538, Class 1 confidence = 0.8462\n",
            "Input 98: Class 0 confidence = 0.5376, Class 1 confidence = 0.4624\n",
            "Input 99: Class 0 confidence = 0.9831, Class 1 confidence = 0.0169\n",
            "Input 100: Class 0 confidence = 0.9503, Class 1 confidence = 0.0497\n",
            "Input 101: Class 0 confidence = 0.9926, Class 1 confidence = 0.0074\n",
            "Input 102: Class 0 confidence = 0.1460, Class 1 confidence = 0.8540\n",
            "Input 103: Class 0 confidence = 0.0354, Class 1 confidence = 0.9646\n",
            "Input 104: Class 0 confidence = 0.2988, Class 1 confidence = 0.7012\n",
            "Input 105: Class 0 confidence = 0.9647, Class 1 confidence = 0.0353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask-expr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2yvO2162tNRd",
        "outputId": "ee2a1dd2-c197-4a32-c4dc-bb531426cddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dask-expr\n",
            "  Downloading dask_expr-1.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting dask==2024.9.0 (from dask-expr)\n",
            "  Downloading dask-2024.9.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from dask-expr) (14.0.2)\n",
            "Requirement already satisfied: pandas>=2 in /usr/local/lib/python3.10/dist-packages (from dask-expr) (2.1.4)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->dask-expr) (8.1.7)\n",
            "Collecting cloudpickle>=3.0.0 (from dask==2024.9.0->dask-expr)\n",
            "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->dask-expr) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->dask-expr) (24.1)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->dask-expr) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->dask-expr) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->dask-expr) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->dask-expr) (8.5.0)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=2->dask-expr) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2->dask-expr) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2->dask-expr) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2->dask-expr) (2024.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask==2024.9.0->dask-expr) (3.20.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask==2024.9.0->dask-expr) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2->dask-expr) (1.16.0)\n",
            "Downloading dask_expr-1.1.14-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.6/242.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask-2024.9.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: cloudpickle, dask, dask-expr\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 2.2.1\n",
            "    Uninstalling cloudpickle-2.2.1:\n",
            "      Successfully uninstalled cloudpickle-2.2.1\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2024.8.0\n",
            "    Uninstalling dask-2024.8.0:\n",
            "      Successfully uninstalled dask-2024.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "distributed 2024.8.0 requires dask==2024.8.0, but you have dask 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpickle-3.0.0 dask-2024.9.0 dask-expr-1.1.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "model = lgb.LGBMClassifier(force_col_wise=True)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "auc = np.round(roc_auc_score(y_test, y_pred), 10)\n",
        "print(auc)\n",
        "f1 = np.round(f1_score(y_test, y_pred), 10)\n",
        "print(f1)\n",
        "recall = np.round(recall_score(y_test, y_pred), 10)\n",
        "print(recall)\n",
        "precision = np.round(precision_score(y_test, y_pred), 10)\n",
        "print(precision)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_jYYbYbtEOS",
        "outputId": "cd3ae3e9-44f8-43c2-d35c-466fa1529d6c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 216, number of negative: 212\n",
            "[LightGBM] [Info] Total Bins 3360\n",
            "[LightGBM] [Info] Number of data points in the train set: 428, number of used features: 32\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504673 -> initscore=0.018692\n",
            "[LightGBM] [Info] Start training from score 0.018692\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Accuracy: 0.9444444444444444\n",
            "0.9443681319\n",
            "0.9423076923\n",
            "0.9423076923\n",
            "0.9423076923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "auc = np.round(roc_auc_score(y_test, y_pred), 10)\n",
        "print(auc)\n",
        "f1 = np.round(f1_score(y_test, y_pred), 10)\n",
        "print(f1)\n",
        "recall = np.round(recall_score(y_test, y_pred), 10)\n",
        "print(recall)\n",
        "precision = np.round(precision_score(y_test, y_pred), 10)\n",
        "print(precision)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H0AUZZ0-rhJO",
        "outputId": "3300f6ef-3812-4463-df60-94f9c4aad0e9"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7685185185185185\n",
            "0.7651098901\n",
            "0.7368421053\n",
            "0.6730769231\n",
            "0.8139534884\n"
          ]
        }
      ]
    }
  ]
}